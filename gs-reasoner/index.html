<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Reasoning in Space via Grounding in the World">
  <meta name="keywords" content="Spatial Reasoning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reasoning in Space via Grounding in the World</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="/3dvision.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="font-size: 2.7rem;">Reasoning in Space via Grounding in the World</h1>
          <a target="_blank" style="color: #0F52BA; font-size: 30px; text-decoration: none; font-weight: bold;"><b>Sota on VSI-Bench</b> ğŸš€</a>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yiming-cc.github.io/">Yiming Chen</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://qizekun.github.io/">Zekun Qi</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://zhangwenyao1.github.io/">Wenyao Zhang</a><sup>5,6</sup>,
            </span>
            <span class="author-block">
              <a href="https://jinx-ustc.github.io/jinxin.github.io/">Xin Jin</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a href="https://lzrobots.github.io/">Li Zhang</a><sup>2,7*</sup>,
            </span>
            <span class="author-block">
              <a href="https://ethliup.github.io/">Peidong Liu</a><sup>1*</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Westlake University</span>
            <span class="author-block"><sup>2</sup>Shanghai Innovation Institute</span>
            <span class="author-block"><sup>3</sup>Zhejiang University</span>
            <span class="author-block"><sup>4</sup>Tsinghua University</span>
            <span class="author-block"><sup>5</sup>Shanghai Jiao Tong University</span>
            <span class="author-block"><sup>6</sup>Eastern Institute of Technology</span>
            <span class="author-block"><sup>7</sup>Fudan University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2510.13800"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/WU-CVGL/GS-Reasoner"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/ymccccc/gs-reasoner-68efc95783fb92bb44269f7a"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Huggingface</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="video-container">
        <video id="teaser" muted loop playsinline height="100%">
          <source src="./static/videos/demo_real_world_compress.mp4"
                  type="video/mp4">
        </video>
        <div class="play-button-overlay" id="playButtonOverlay">
          <button class="play-button" id="playButton">
            <i class="fas fa-play"></i>
          </button>
        </div>
        
        <!-- è§†é¢‘æ§åˆ¶å™¨ -->
        <div class="video-controls" id="videoControls">
          <div class="progress-container">
            <div class="progress-bar" id="progressBar">
              <div class="progress-filled" id="progressFilled"></div>
              <div class="progress-handle" id="progressHandle"></div>
            </div>
          </div>
          
          <div class="controls-row">
            <div class="left-controls">
              <button class="control-btn" id="playPauseBtn">
                <i class="fas fa-play"></i>
              </button>
              <button class="control-btn" id="muteBtn">
                <i class="fas fa-volume-up"></i>
              </button>
              <div class="volume-container">
                <input type="range" class="volume-slider" id="volumeSlider" min="0" max="1" step="0.1" value="1">
              </div>
              <span class="time-display" id="timeDisplay">0:00 / 0:00</span>
            </div>
            
            <div class="right-controls">
              <button class="control-btn" id="fullscreenBtn">
                <i class="fas fa-expand"></i>
              </button>
            </div>
          </div>
        </div>
      </div>
      <!-- <h2 class="subtitle has-text-centered">
        video here
      </h2> -->

      <!-- <img src="./static/images/teaser.png" alt="Teaser" style="max-width: 100%; height: auto;"> -->
       <div class="columns is-centered has-text-centered" style="margin-top: 5px;">
        <div class="content has-text-justified">
          The video is captured in the wild without sensory 3D inputs, highlighting the strong generalization capability of our model.
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            In this paper, we claim that 3D visual grounding is the cornerstone of spatial reasoning and introduce the <strong>Grounded-Spatial Reasoner (GS-Reasoner)</strong> to explore the effective spatial representations that bridge the gap between them.
            Existing 3D LLMs suffer from the absence of a unified 3D representation capable of jointly capturing semantic and geometric information.
            This deficiency is manifested either in poor performance on grounding or in an excessive reliance on external modules, ultimately hindering the seamless integration of grounding and spatial reasoning.
            To address this, we propose a simple yet effective <strong>dual-path pooling</strong> mechanism that tightly aligns geometric features with both semantic and positional cues, constructing a unified image patch-based 3D representation that encapsulates all essential information without increasing the number of input tokens. Leveraging this holistic representation, GS-Reasoner is the first 3D LLM that achieves autoregressive grounding entirely without external modules while delivering performance comparable to state-of-the-art models, establishing a unified and self-contained framework for 3D spatial reasoning.
            To further bridge grounding and spatial reasoning, we introduce the <strong>Grounded Chain-of-Thought (GCoT)</strong> dataset. This dataset is meticulously curated to include both 3D bounding box annotations for objects referenced in reasoning questions and step-by-step reasoning paths that integrate grounding as a core component of the problem-solving process.
            Extensive experiments demonstrate that GS-Reasoner achieves impressive results on 3D visual grounding, which in turn significantly enhances its spatial reasoning capabilities, leading to state-of-the-art performance.

        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Method Overview -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Method Overview</h2>
            <div class="has-text-centered">
              <!-- <iframe src="./static/images/pipeline_final.pdf" width="100%" 
            height="300px" style="border: none;"></iframe> -->
              <img src="./static/images/pipeline.png" alt="Method Pipeline" style="max-width: 100%; height: auto;">
              <div class="content has-text-justified">
                <strong>Overview of GS-Reasoner framework.</strong> Our method builds a semantic-geometric hybrid 3D scene representation, enabling 3D LLM to perform 3D visual grounding autoregressively, which allows grounding to be integrated as a chain-of-thought within the spatial reasoning process. 
              </div>
            </div>
        </div>
      </div>
    </div>
    <!--/ Method Overview -->

    <!-- Dataset Overview -->
    <div class="columns is-centered has-text-centered" style="margin-top: 5rem;">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Dataset Overview</h2>
            <div class="has-text-centered">
              <!-- <iframe src="./static/images/pipeline_final.pdf" width="100%" 
            height="300px" style="border: none;"></iframe> -->
              <img src="./static/images/Dataset.png" alt="Dataset Pipeline" style="max-width: 100%; height: auto;">
              <div class="content has-text-justified">
                <strong>Overview of Grounded Chain-of-Thought (GCoT) Dataset.</strong> We first construct spatial QA pairs without CoT, and then prompt GPT-4o to generate CoT paths based on the bird's-eye view, object information, and QA pairs.
              </div>
            </div>
        </div>
      </div>
    </div>
    <!--/ Dataset Overview -->


    <!-- Performance. -->
    <div class="columns is-centered has-text-centered" style="margin-top: 5rem;">
      <div class="column">
        <h2 class="title is-3">Performance</h2>

        <h3 class="title is-5">Spatial Reasoning (VSI-Bench)</h3>
        <img src="./static/images/sp_tab.png" alt="Spatial Reasoning Table" style="max-width: 100%; height: auto;">
        <div class="content has-text-justified">
          <strong>Evaluation on VSI-Bench.</strong> GS-Reasoner achieves state-of-the-art performance on most tasks, with further gains using more accurate (ground-truth) depth.
        </div>

        <h3 class="title is-5" style="margin-top:3rem;">3D Visual Grounding</h3>
        <img src="./static/images/3dvg_tab.png" alt="3D Visual Grounding Table" style="max-width: 100%; height: auto;">
        <div class="content has-text-justified">
          <strong>Evaluation on 3D Visual Grounding.</strong> GS-Reasoner achieves performance comparable to 3D LLMs using mesh proposals or external grounding, without any external components.
        </div>

        <h3 class="title is-5" style="margin-top:3rem;">General 3D Tasks</h3>
        <img src="./static/images/g3d_tab.png" alt="General 3D Tasks Table" style="max-width: 100%; height: auto;">
        <div class="content has-text-justified">
          <strong>Evaluation on General 3D Tasks.</strong> GS-Reasoner outperforms state-of-the-art 3D LLMs on Scan2Cap and achieves comparable results on ScanQA and SQA3D.
        </div>

      </div>
    </div>
    <!--/ Performance. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{chen2025reasoningspacegroundingworld
      title={Reasoning in Space via Grounding in the World}, 
      author={Yiming Chen and Zekun Qi and Wenyao Zhang and Xin Jin and Li Zhang and Peidong Liu},
      year={2025},
      eprint={2510.13800},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2510.13800}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> that kindly open sourced the template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const video = document.getElementById('teaser');
  const playButton = document.getElementById('playButton');
  const playButtonOverlay = document.getElementById('playButtonOverlay');
  const videoControls = document.getElementById('videoControls');
  
  // æ§åˆ¶å™¨å…ƒç´ 
  const playPauseBtn = document.getElementById('playPauseBtn');
  const muteBtn = document.getElementById('muteBtn');
  const volumeSlider = document.getElementById('volumeSlider');
  const progressBar = document.getElementById('progressBar');
  const progressFilled = document.getElementById('progressFilled');
  const progressHandle = document.getElementById('progressHandle');
  const timeDisplay = document.getElementById('timeDisplay');
  const fullscreenBtn = document.getElementById('fullscreenBtn');
  
  let isDragging = false;
  let controlsTimeout;
  
  // æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
  function formatTime(seconds) {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  }
  
  // æ›´æ–°è¿›åº¦æ¡
  function updateProgress() {
    if (video.duration) {
      const progress = (video.currentTime / video.duration) * 100;
      progressFilled.style.width = progress + '%';
      progressHandle.style.left = progress + '%';
    }
  }
  
  // æ›´æ–°æ—¶é—´æ˜¾ç¤º
  function updateTime() {
    timeDisplay.textContent = `${formatTime(video.currentTime)} / ${formatTime(video.duration)}`;
  }
  
  // æ˜¾ç¤ºæ§åˆ¶å™¨
  function showControls() {
    videoControls.classList.add('show');
    clearTimeout(controlsTimeout);
    controlsTimeout = setTimeout(() => {
      if (!video.paused) {
        videoControls.classList.remove('show');
      }
    }, 3000);
  }
  
  // éšè—æ§åˆ¶å™¨
  function hideControls() {
    videoControls.classList.remove('show');
  }
  
  // æ’­æ”¾/æš‚åœåŠŸèƒ½
  function togglePlayPause() {
    if (video.paused) {
      video.play();
    } else {
      video.pause();
    }
  }
  
  // é™éŸ³/å–æ¶ˆé™éŸ³
  function toggleMute() {
    video.muted = !video.muted;
    volumeSlider.value = video.muted ? 0 : video.volume;
  }
  
  // å…¨å±åŠŸèƒ½
  function toggleFullscreen() {
    if (!document.fullscreenElement) {
      video.requestFullscreen().catch(err => {
        console.log('Error attempting to enable fullscreen:', err);
      });
    } else {
      document.exitFullscreen();
    }
  }
  
  // è®¾ç½®è§†é¢‘æ—¶é—´
  function setVideoTime(percent) {
    video.currentTime = (percent / 100) * video.duration;
  }
  
  // äº‹ä»¶ç›‘å¬å™¨
  
  // ç‚¹å‡»æ’­æ”¾æŒ‰é’®å¼€å§‹æ’­æ”¾è§†é¢‘
  playButton.addEventListener('click', function() {
    video.play();
    playButtonOverlay.classList.add('hidden');
    showControls();
  });
  
  // æ’­æ”¾/æš‚åœæŒ‰é’®
  playPauseBtn.addEventListener('click', togglePlayPause);
  
  // é™éŸ³æŒ‰é’®
  muteBtn.addEventListener('click', toggleMute);
  
  // éŸ³é‡æ»‘å—
  volumeSlider.addEventListener('input', function() {
    video.volume = this.value;
    video.muted = this.value == 0;
  });
  
  // å…¨å±æŒ‰é’®
  fullscreenBtn.addEventListener('click', toggleFullscreen);
  
  // è¿›åº¦æ¡ç‚¹å‡»
  progressBar.addEventListener('click', function(e) {
    const rect = this.getBoundingClientRect();
    const percent = ((e.clientX - rect.left) / rect.width) * 100;
    setVideoTime(percent);
  });
  
  // è¿›åº¦æ¡æ‹–æ‹½
  progressHandle.addEventListener('mousedown', function(e) {
    isDragging = true;
    e.preventDefault();
  });
  
  document.addEventListener('mousemove', function(e) {
    if (isDragging) {
      const rect = progressBar.getBoundingClientRect();
      const percent = Math.max(0, Math.min(100, ((e.clientX - rect.left) / rect.width) * 100));
      setVideoTime(percent);
    }
  });
  
  document.addEventListener('mouseup', function() {
    isDragging = false;
  });
  
  // è§†é¢‘äº‹ä»¶ç›‘å¬
  video.addEventListener('play', function() {
    playButtonOverlay.classList.add('hidden');
    playPauseBtn.innerHTML = '<i class="fas fa-pause"></i>';
    showControls();
  });
  
  video.addEventListener('pause', function() {
    playButtonOverlay.classList.remove('hidden');
    playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
    showControls();
  });
  
  video.addEventListener('ended', function() {
    playButtonOverlay.classList.remove('hidden');
    playPauseBtn.innerHTML = '<i class="fas fa-play"></i>';
    video.currentTime = 0;
    updateProgress();
  });
  
  video.addEventListener('timeupdate', function() {
    if (!isDragging) {
      updateProgress();
    }
    updateTime();
  });
  
  video.addEventListener('loadedmetadata', function() {
    updateTime();
  });
  
  video.addEventListener('volumechange', function() {
    muteBtn.innerHTML = video.muted ? '<i class="fas fa-volume-mute"></i>' : '<i class="fas fa-volume-up"></i>';
    volumeSlider.value = video.muted ? 0 : video.volume;
  });
  
  // é¼ æ ‡ç§»åŠ¨æ˜¾ç¤ºæ§åˆ¶å™¨
  video.addEventListener('mousemove', showControls);
  video.addEventListener('mouseleave', function() {
    if (!video.paused) {
      hideControls();
    }
  });
  
  // ç‚¹å‡»è§†é¢‘æ’­æ”¾/æš‚åœ
  video.addEventListener('click', function(e) {
    if (e.target === video) {
      togglePlayPause();
    }
  });
  
  // é”®ç›˜æ§åˆ¶
  document.addEventListener('keydown', function(e) {
    if (video === document.activeElement || video.contains(document.activeElement)) {
      switch(e.code) {
        case 'Space':
          e.preventDefault();
          togglePlayPause();
          break;
        case 'KeyM':
          e.preventDefault();
          toggleMute();
          break;
        case 'KeyF':
          e.preventDefault();
          toggleFullscreen();
          break;
        case 'ArrowLeft':
          e.preventDefault();
          video.currentTime = Math.max(0, video.currentTime - 10);
          break;
        case 'ArrowRight':
          e.preventDefault();
          video.currentTime = Math.min(video.duration, video.currentTime + 10);
          break;
      }
    }
  });
  
  // å…¨å±çŠ¶æ€å˜åŒ–
  document.addEventListener('fullscreenchange', function() {
    fullscreenBtn.innerHTML = document.fullscreenElement ? 
      '<i class="fas fa-compress"></i>' : '<i class="fas fa-expand"></i>';
  });
});
</script>

</body>
</html>
